{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from osgeo import gdal, osr\n",
    "import pandas as pd\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ncols         9720\n",
    "#nrows         9159\n",
    "#xllcorner     -27.174992029555\n",
    "#yllcorner     -37.791665508412\n",
    "#cellsize      0.0083333333333333\n",
    "#NODATA_value  -9999\n",
    "# seperated by a space\n",
    "\n",
    "from osgeo import gdal, osr\n",
    "\n",
    "AEZ_raster_in=os.path.join(\"data\", \"raster\",\"AEZ_2009\",\"afr_aez09.asc\")\n",
    "AEZ_raster_csv=os.path.join(\"data\", \"raster\",\"AEZ_2009\",\"afr_aez09.csv\")\n",
    "\n",
    "AEZ_raster_out=os.path.join(\"data\", \"raster\",\"AEZ_2009\",\"afr_aez09.tif\")\n",
    "\n",
    "with open(AEZ_raster_in, 'r', encoding = 'ANSI') as fp:\n",
    "    data = fp.read()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asc_header_data=data[:153]\n",
    "AEZ_raster_headers=os.path.join(\"data\", \"raster\",\"AEZ_2009\",\"afr_aez09_headers.asc\")\n",
    "\n",
    "g = open(AEZ_raster_headers,'w',encoding='ANSI')\n",
    "\n",
    "# write the data (but not the first 153 characters, which are metadata)\n",
    "g.write(asc_header_data)\n",
    "\n",
    "# close the new csv file\n",
    "g.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_asc_data=data[153:]\n",
    "data=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = open(AEZ_raster_csv,'w',encoding='ANSI')\n",
    "\n",
    "# write the data (but not the first 153 characters, which are metadata)\n",
    "g.write(all_asc_data)\n",
    "\n",
    "# close the new csv file\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AEZ_data_frame=pd.read_csv(AEZ_raster_csv,\n",
    "                           low_memory=False, \n",
    "                           encoding='ANSI', \n",
    "                           header=None, \n",
    "                           sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AEZ_data_frame.shape # should be 9159 rows and 9720 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_data_types=AEZ_data_frame.dtypes\n",
    "all_data_types.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AEZ_df_as_float = pd.DataFrame(np.zeros(AEZ_data_frame.shape), columns=None)\n",
    "\n",
    "partial_failure=[]\n",
    "\n",
    "for row in AEZ_data_frame.index:\n",
    "    try:\n",
    "        AEZ_df_as_float.iloc[row,:]=AEZ_data_frame.iloc[row,:].astype(float)\n",
    "    except ValueError:\n",
    "        for column in AEZ_data_frame.columns:\n",
    "            try:\n",
    "                AEZ_df_as_float.iloc[row,column]=float(AEZ_data_frame.iloc[row,column])\n",
    "                if row in partial_failure:\n",
    "                    continue\n",
    "                else:\n",
    "                    partial_failure.append(row)\n",
    "            except ValueError:\n",
    "                 AEZ_df_as_float.iloc[row,column] = np.nan\n",
    "\n",
    "#print(partial_failure) use this print statement to see the rows which contin only NAs\n",
    "    \n",
    "    \n",
    "\n",
    "# there are some rows with data in them which is not numerical and looks like weird symbols when you open the asc file as plaintext\n",
    "# I plotted the data to see where these are and whether they explain why the data is longer than expected\n",
    "# to do that they need to be recorded as missing values rather than weird values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# creating an array of every nth point point\n",
    "number_of_rows=AEZ_df_as_float.shape[0]\n",
    "number_of_columns=AEZ_df_as_float.shape[1]\n",
    "\n",
    "number_of_data_points_to_skip = 10 # take every 10th point\n",
    "\n",
    "total_row_intervals = int(np.divide(number_of_rows,number_of_data_points_to_skip)) #rounds down the division to the nearest integer\n",
    "total_column_intervals = int(np.divide(number_of_columns, number_of_data_points_to_skip)) #rounds down the division to the nearest integer\n",
    "\n",
    "total_number_of_data_points=total_row_intervals*total_column_intervals\n",
    "rows_of_array = np.zeros(total_number_of_data_points)\n",
    "columns_of_array = np.zeros(total_number_of_data_points)\n",
    "aez_value = np.zeros(total_number_of_data_points)\n",
    "\n",
    "for skipped_column in range(total_column_intervals): \n",
    "    for skipped_row in range(total_row_intervals):\n",
    "        data_index = skipped_row + total_row_intervals*skipped_column\n",
    "                \n",
    "        columns_of_array[data_index]= AEZ_df_as_float.columns[skipped_column*number_of_data_points_to_skip]\n",
    "        rows_of_array[data_index] = AEZ_df_as_float.index[skipped_row*number_of_data_points_to_skip]\n",
    "        aez_value[data_index] = AEZ_df_as_float.iloc[skipped_row*number_of_data_points_to_skip,skipped_column*number_of_data_points_to_skip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting as array\n",
    "fig, ax= plt.subplots()\n",
    "plt.scatter(x=columns_of_array,y=rows_of_array.max()-rows_of_array,c=aez_value,marker='s', s=.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting using imshow\n",
    "\n",
    "#AEZ_array=AEZ_df_as_float.to_numpy()\n",
    "#fig,ax=plt.subplots(figsize=(19.4,18.6))\n",
    "#plt.imshow(AEZ_array, aspect=\"auto\") \n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "africa_aez_temp = AEZ_df_as_float.dropna(axis=0, how='all') #dropping rows with 'all' missing values\n",
    "africa_aez_temp = africa_aez_temp.dropna(axis=1, how='all') #dropping columns with 'all' missing values\n",
    "africa_aez_temp = africa_aez_temp.drop(AEZ_df_as_float.index[4324]) #dropping rows with 'all' missing values\n",
    "africa_aez_temp = africa_aez_temp.fillna(-9999) #dropping columns with 'all' missing values\n",
    "africa_aez_no_null=africa_aez_temp.astype(\"int64\")\n",
    "\n",
    "africa_aez_temp = None # overwrite temp to free up memory\n",
    "#AEZ_df_as_float=None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "africa_aez_no_null.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AEZ_array=africa_aez_no_null.to_numpy()\n",
    "AEZ_array=africa_aez_no_null.astype(int)\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(19.4,18.6))\n",
    "plt.imshow(AEZ_array, aspect=\"auto\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AEZ_array.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(AEZ_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AEZ_raster_cleaned=os.path.join(\"data\", \"raster\",\"AEZ_2009\",\"afr_aez_cleaned.asc\")\n",
    "np.savetxt(AEZ_raster_cleaned,AEZ_array.astype(int), delimiter=\" \", encoding=\"ANSI\", fmt=\"%i\", newline='\\r\\n')\n",
    "#AEZ_array=None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_loaded=np.loadtxt(AEZ_raster_cleaned)\n",
    "\n",
    "with open(AEZ_raster_cleaned,'r',encoding='ANSI') as f:\n",
    "\n",
    "# write the data (but not the first 153 characters, which are metadata)\n",
    "    raster_data=f.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(raster_data)\n",
    "list(set(raster_data)) # checking all of the individual characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(AEZ_raster_headers,'r',encoding='ANSI') as f:\n",
    "\n",
    "# write the data (but not the first 153 characters, which are metadata)\n",
    "    header_data=f.read()\n",
    "\n",
    "header_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_file=header_data+raster_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_file[1:200]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AEZ_RASTER_FINAL=os.path.join(\"data\", \"raster\",\"AEZ_2009\",\"AEZ_FINAL.asc\")\n",
    "\n",
    "with open(AEZ_RASTER_FINAL,'w',encoding='ANSI') as f:\n",
    "\n",
    "# write the data (but not the first 153 characters, which are metadata)\n",
    "    f.write(merged_file)\n",
    "\n",
    "# close the new csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code below used to identify the NULL row which remained #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding rows that all have the same value. This only includes rows with -9999\n",
    "unique_array_values=[]\n",
    "rows_with_value=[]\n",
    "for rows in africa_aez_no_null.index:\n",
    "    if len(list(pd.unique(africa_aez_no_null.loc[rows,:])))==1:\n",
    "        if list(pd.unique(africa_aez_no_null.loc[rows,:])) in unique_array_values:\n",
    "            rows_with_value.append(rows)\n",
    "            continue\n",
    "        else:\n",
    "            unique_array_values.append(list(pd.unique(africa_aez_no_null.loc[rows,:])))\n",
    "            rows_with_value.append(rows)\n",
    "#unique_array_values\n",
    "#rows_with_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNaN(num):\n",
    "    return num != num\n",
    "\n",
    "unique_array_values=[]\n",
    "rows_with_nan=[]\n",
    "for rows in africa_aez_no_null.index:\n",
    "    unique_values_for_row=list(pd.unique(africa_aez_no_null.loc[rows,:]))\n",
    "    for unique_value in unique_values_for_row:\n",
    "        if isNaN(unique_value):\n",
    "            rows_with_nan.append(rows)\n",
    "        if unique_value in unique_array_values:\n",
    "            continue\n",
    "        else:\n",
    "            unique_array_values.append(unique_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_array_values\n",
    "rows_with_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#africa_aez_no_null.loc[9720,:]\n",
    "#see what is on either side of the nan values\n",
    "either_side_4166=[]\n",
    "either_side_4324=[]\n",
    "either_side_4361=[]\n",
    "either_side_4369=[]\n",
    "\n",
    "\n",
    "row_number=4166\n",
    "dataframe=africa_aez_no_null\n",
    "def find_first_nan_value(row_number,dataframe):\n",
    "    subset=dataframe.loc[row_number,:]\n",
    "    na_location=[]\n",
    "    for i in subset.index:\n",
    "        if i >0 and i<9719:\n",
    "            value=subset[i]\n",
    "            left_subset=i-1\n",
    "            right_subset=i+1\n",
    "            value_left=subset[left_subset]\n",
    "            value_right=subset[right_subset]\n",
    "            if isNaN(value):\n",
    "                if (isNaN(value_left)==False) or (isNaN(value_right)==False):\n",
    "                    list_to_print=[value_left,value,value_right]\n",
    "                    na_location.append(i)\n",
    "    first_na_location=min(na_location)\n",
    "    return first_na_location;\n",
    "\n",
    "\n",
    "first_na_4166=find_first_nan_value(4166,dataframe)\n",
    "first_na_4324=find_first_nan_value(4324,dataframe)\n",
    "first_na_4361=find_first_nan_value(4361,dataframe)\n",
    "first_na_4369=find_first_nan_value(4369,dataframe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#africa_aez_no_null.loc[4166,(first_na_4166-100):(first_na_4166+100)]\n",
    "africa_aez_no_null.loc[4166,].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#africa_aez_no_null.loc[4324,(first_na_4324-100):(first_na_4324+100)]\n",
    "\n",
    "africa_aez_no_null.loc[4324,].plot()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#africa_aez_no_null.loc[4361,(first_na_4361-100):(first_na_4361+100)]\n",
    "africa_aez_no_null.loc[4361,].plot()\n",
    "#324 has almost all NA values accross the land, so it will be dropped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#africa_aez_no_null.loc[4369,(first_na_4369-100):(first_na_4369+100)]\n",
    "africa_aez_no_null.loc[4369,].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AEZ_raster_cleaned=os.path.join(\"data\", \"raster\",\"AEZ_2009\",\"afr_aez_cleaned.asc\")\n",
    "AEZ_array.shape\n",
    "#np.savetxt(AEZ_raster_cleaned,AEZ_array, delimiter=\" \", newline='\\n', encoding=\"ANSI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
